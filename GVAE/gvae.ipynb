{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0838df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.conv import TransformerConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.utils import dense_to_sparse, to_dense_adj, remove_self_loops\n",
    "from torch_geometric.nn import BatchNorm\n",
    "from torch.nn import BatchNorm1d\n",
    "from config import DEVICE as device\n",
    "\n",
    "class GVAE(nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(GVAE, self).__init__()\n",
    "        encoder_embedding_size = 64\n",
    "        edge_dim = 11\n",
    "        self.latent_embedding_size = 16\n",
    "        decoder_size=128\n",
    "        \n",
    "\n",
    "        \n",
    "        self.conv1 = TransformerConv(feature_size, \n",
    "                                    encoder_embedding_size, \n",
    "                                    heads=4, \n",
    "                                    concat=False,\n",
    "                                    beta=True,\n",
    "                                    edge_dim=edge_dim)\n",
    "        self.bn1 = BatchNorm(encoder_embedding_size)\n",
    "        self.conv2 = TransformerConv(encoder_embedding_size, \n",
    "                                    encoder_embedding_size, \n",
    "                                    heads=4, \n",
    "                                    concat=False,\n",
    "                                    beta=True,\n",
    "                                    edge_dim=edge_dim)\n",
    "        self.bn2 = BatchNorm(encoder_embedding_size)\n",
    "        self.conv3 = TransformerConv(encoder_embedding_size, \n",
    "                                    encoder_embedding_size, \n",
    "                                    heads=4, \n",
    "                                    concat=False,\n",
    "                                    beta=True,\n",
    "                                    edge_dim=edge_dim)\n",
    "        self.bn3 = BatchNorm(encoder_embedding_size)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.mu_transform = TransformerConv(encoder_embedding_size, \n",
    "                                            self.latent_embedding_size,\n",
    "                                            heads=4,\n",
    "                                            concat=False,\n",
    "                                            beta=True,\n",
    "                                            edge_dim=edge_dim\n",
    "                                           )\n",
    "        self.logvar_transform = TransformerConv(encoder_embedding_size, \n",
    "                                            self.latent_embedding_size,\n",
    "                                                heads=4,\n",
    "                                                concat=False,\n",
    "                                                beta=True,\n",
    "                                                edge_dim=edge_dim\n",
    "                                               )\n",
    "\n",
    "        \n",
    "        self.decoder_dense_1 = Linear(self.latent_embedding_size*2, decoder_size)\n",
    "        self.decoder_bn_1 = BatchNorm1d(decoder_size)\n",
    "        self.decoder_dense_2 = Linear(self.latent_embedding_size*2, decoder_size)\n",
    "        self.decoder_bn_2 = BatchNorm1d(decoder_size)\n",
    "        self.decoder_dense_3 = Linear(self.latent_embedding_size*2, decoder_size)\n",
    "        self.decoder_bn_3 = BatchNorm1d(decoder_size)\n",
    "        self.decoder_dense_4 = Linear(decoder_size,1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def encode(self, x, edge_attr, edge_index):\n",
    "        \n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x, edge_index, edge_attr).relu()\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv3(x, edge_index, edge_attr).relu()\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        \n",
    "        mu = self.mu_transform(x, edge_index, edge_attr)\n",
    "        logvar = self.logvar_transform(x, edge_index, edge_attr)\n",
    "        return mu, logvar\n",
    "\n",
    "    def decode_graph(self, graph_z):  \n",
    "        \n",
    "        z = self.linear_1(graph_z).relu()\n",
    "        z = self.linear_2(z).relu()\n",
    "        \n",
    "        atom_logits = self.atom_decode(z)\n",
    "        \n",
    "        edge_logits = self.edge_decode(z)\n",
    "\n",
    "        return atom_logits, edge_logits\n",
    "\n",
    "\n",
    "    def decode(self, z, batch_index):\n",
    "        inputs=[]\n",
    "        \n",
    "        for graph_id in torch.unique(batch_index):\n",
    "            \n",
    "            graph_mask=torch.eq(batch_index,graph_id)\n",
    "            graph_z = z[graph_mask]\n",
    "\n",
    "            \n",
    "            edge_indices=torch.triu_indices(graph_z.shape[0],graph_z.shape[0], offset=1)\n",
    "\n",
    "            \n",
    "            dim = self.latent_embedding_size\n",
    "            source_indices = torch.reshape(edge_indices[0].repeat_interleave(dim), (edge_indices.shape[1], dim))\n",
    "            target_indices = torch.reshape(edge_indices[1].repeat_interleave(dim), (edge_indices.shape[1], dim))\n",
    "\n",
    "        \n",
    "            sources_feats = torch.gather(graph_z, 0, source_indices.to(device))\n",
    "            target_feats = torch.gather(graph_z, 0, target_indices.to(device))\n",
    "\n",
    "            \n",
    "            graph_inputs = torch.cat([sources_feats, target_feats], axis=1)\n",
    "            inputs.append(graph_inputs)\n",
    "\n",
    "        \n",
    "        inputs = torch.cat(inputs)\n",
    "\n",
    "        \n",
    "        x = self.decoder_dense_1(inputs).relu()\n",
    "        x = self.decoder_bn_1(x)\n",
    "        x = self.decoder_dense_2(inputs).relu()\n",
    "        x = self.decoder_bn_2(x)\n",
    "        x = self.decoder_dense_3(inputs).relu()\n",
    "        x = self.decoder_bn_3(x)\n",
    "        edge_logits = self.decoder_dense_4(x)\n",
    "\n",
    "        return edge_logits\n",
    "\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            \n",
    "            std = torch.exp(logvar)\n",
    "            \n",
    "            eps = torch.randn_like(std)\n",
    "            \n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "        \n",
    "        mu, logvar = self.encode(x, edge_attr, edge_index)\n",
    "        \n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        triu_logits = self.decode(z, batch_index)\n",
    "\n",
    "        return triu_logits, mu, logvar\n",
    "\n",
    "    \n",
    "    \n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
