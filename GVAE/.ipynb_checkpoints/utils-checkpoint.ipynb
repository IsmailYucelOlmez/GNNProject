{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63af599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "import torch\n",
    "import import_ipynb\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger \n",
    "from config import DEVICE as device\n",
    "from config import (SUPPORTED_ATOMS, SUPPORTED_EDGES, MAX_MOLECULE_SIZE, ATOMIC_NUMBERS,\n",
    "                    DISABLE_RDKIT_WARNINGS)\n",
    "\n",
    "# Disable rdkit warnings\n",
    "if DISABLE_RDKIT_WARNINGS:\n",
    "    RDLogger.DisableLog('rdApp.*')  \n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Counts the number of parameters for a Pytorch model\n",
    "    \"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def kl_loss(mu=None, logstd=None):\n",
    "    \"\"\"\n",
    "    Closed formula of the KL divergence for normal distributions\n",
    "    \"\"\"\n",
    "    MAX_LOGSTD = 10\n",
    "    logstd =  logstd.clamp(max=MAX_LOGSTD)\n",
    "    kl_div = -0.5 * torch.mean(torch.sum(1 + 2 * logstd - mu**2 - logstd.exp()**2, dim=1))\n",
    "\n",
    "    # Limit numeric errors\n",
    "    kl_div = kl_div.clamp(max=1000)\n",
    "    return kl_div\n",
    "\n",
    "def slice_graph_targets(graph_id, edge_targets, node_targets, batch_index):\n",
    "    \"\"\"\n",
    "    Slices out the upper triangular part of an adjacency matrix for\n",
    "    a single graph from a large adjacency matrix for a full batch.\n",
    "    For the node features the corresponding section in the batch is sliced out.\n",
    "    --------\n",
    "    graph_id: The ID of the graph (in the batch index) to slice\n",
    "    edge_targets: A dense adjacency matrix for the whole batch\n",
    "    node_targets: A tensor of node labels for the whole batch\n",
    "    batch_index: The node to graph map for the batch\n",
    "    \"\"\"\n",
    "    # Create mask for nodes of this graph id\n",
    "    graph_mask = torch.eq(batch_index, graph_id)\n",
    "    # Row slice and column slice batch targets to get graph edge targets\n",
    "    graph_edge_targets = edge_targets[graph_mask][:, graph_mask]\n",
    "    # Get triangular upper part of adjacency matrix for targets\n",
    "    size = graph_edge_targets.shape[0]\n",
    "    triu_indices = torch.triu_indices(size, size, offset=1)\n",
    "    triu_mask = torch.squeeze(to_dense_adj(triu_indices)).bool()\n",
    "    graph_edge_targets = graph_edge_targets[triu_mask]\n",
    "    # Slice node targets\n",
    "    graph_node_targets = node_targets[graph_mask]\n",
    "    return graph_edge_targets, graph_node_targets\n",
    "\n",
    "def slice_graph_predictions(triu_logits, node_logits, graph_triu_size, triu_start_point, graph_size, node_start_point):\n",
    "    \"\"\"\n",
    "    Slices out the corresponding section from a list of batch triu values.\n",
    "    Given a start point and the size of a graph's triu, simply slices\n",
    "    the section from the batch list.\n",
    "    -------\n",
    "    triu_logits: A batch of triu predictions of different graphs\n",
    "    node_logits: A batch of node predictions with fixed size MAX_GRAPH_SIZE\n",
    "    graph_triu_size: Size of the triu of the graph to slice\n",
    "    triu_start_point: Index of the first node of this graph in the triu batch\n",
    "    graph_size: Max graph size\n",
    "    node_start_point: Index of the first node of this graph in the nodes batch\n",
    "    \"\"\"\n",
    "    # Slice edge logits\n",
    "    graph_logits_triu = torch.squeeze(\n",
    "                    triu_logits[triu_start_point:triu_start_point + graph_triu_size]\n",
    "                    )  \n",
    "    # Slice node logits\n",
    "    graph_node_logits = torch.squeeze(\n",
    "                    node_logits[node_start_point:node_start_point + graph_size]\n",
    "                    ) \n",
    "    return graph_logits_triu, graph_node_logits\n",
    "\n",
    "\n",
    "def slice_edge_type_from_edge_feats(edge_feats):\n",
    "    \"\"\"\n",
    "    This function only works for the MolGraphConvFeaturizer used in the dataset.\n",
    "    It slices the one-hot encoded edge type from the edge feature matrix.\n",
    "    The first 4 values stand for [\"SINGLE\", \"DOUBLE\", \"TRIPLE\", \"AROMATIC\"]. \n",
    "    \"\"\"\n",
    "    edge_types_one_hot = edge_feats[:, :4]\n",
    "    edge_types = edge_types_one_hot.nonzero(as_tuple=False)\n",
    "    # Start index at 1, zero will be no edge\n",
    "    edge_types[:, 1] = edge_types[:, 1] + 1\n",
    "    return edge_types\n",
    "\n",
    "\n",
    "def slice_atom_type_from_node_feats(node_features, as_index=False):\n",
    "    \"\"\"\n",
    "    This function only works for the MolGraphConvFeaturizer used in the dataset.\n",
    "    It slices the one-hot encoded atom type from the node feature matrix.\n",
    "    Unknown atom types are not considered and not expected in the datset.\n",
    "    \"\"\"\n",
    "    supported_atoms = SUPPORTED_ATOMS\n",
    "    atomic_numbers =  ATOMIC_NUMBERS\n",
    "\n",
    "    # Slice first X entries from the node feature matrix\n",
    "    atom_types_one_hot = node_features[:, :len(supported_atoms)]\n",
    "    if not as_index:\n",
    "        # Map the index to the atomic number\n",
    "        atom_numbers_dummy = torch.Tensor(atomic_numbers).repeat(atom_types_one_hot.shape[0], 1)\n",
    "        atom_types = torch.masked_select(atom_numbers_dummy, atom_types_one_hot.bool())\n",
    "    else:\n",
    "        atom_types = torch.argmax(atom_types_one_hot, dim=1)\n",
    "    return atom_types\n",
    "\n",
    "def to_one_hot(x, options):\n",
    "    \"\"\"\n",
    "    Converts a tensor of values to a one-hot vector\n",
    "    based on the entries in options.\n",
    "    \"\"\"\n",
    "    return torch.nn.functional.one_hot(x.long(), len(options))\n",
    "\n",
    "def squared_difference(input, target):\n",
    "    return (input - target) ** 2\n",
    "\n",
    "\n",
    "def triu_to_dense(triu_values, num_nodes):\n",
    "    \"\"\"\n",
    "    Converts a triangular upper part of a matrix as flat vector\n",
    "    to a squared adjacency matrix with a specific size (num_nodes).\n",
    "    \"\"\"\n",
    "    dense_adj = torch.zeros((num_nodes, num_nodes)).to(device).float()\n",
    "    triu_indices = torch.triu_indices(num_nodes, num_nodes, offset=1)\n",
    "    tril_indices = torch.tril_indices(num_nodes, num_nodes, offset=-1)\n",
    "    dense_adj[triu_indices[0], triu_indices[1]] = triu_values\n",
    "    dense_adj[tril_indices[0], tril_indices[1]] = triu_values\n",
    "    return dense_adj\n",
    "\n",
    "\n",
    "def triu_to_3d_dense(triu_values, num_nodes, depth=len(SUPPORTED_EDGES)):\n",
    "    \"\"\"\n",
    "    Converts the triangular upper part of a matrix\n",
    "    for several dimensions into a 3d tensor.\n",
    "    \"\"\"\n",
    "    # Create placeholder for 3d matrix\n",
    "    adj_matrix_3d = torch.empty((num_nodes, num_nodes, depth), dtype=torch.float, device=device)\n",
    "    for edge_type in range(len(SUPPORTED_EDGES)):\n",
    "        adj_mat_edge_type = triu_to_dense(triu_values[:, edge_type].float(), num_nodes)\n",
    "        adj_matrix_3d[:, :, edge_type] = adj_mat_edge_type\n",
    "    return adj_matrix_3d\n",
    "\n",
    "def calculate_node_edge_pair_loss(node_tar, edge_tar, node_pred, edge_pred):\n",
    "    \"\"\"\n",
    "    Calculates a loss based on the sum of node-edge pairs.\n",
    "    node_tar:  [nodes, supported atoms]\n",
    "    node_pred: [max nodes, supported atoms + 1]\n",
    "    edge_tar:  [triu values for target nodes, supported edges]\n",
    "    edge_pred: [triu values for predicted nodes, supported edges]\n",
    "\n",
    "    \"\"\"\n",
    "    # Recover full 3d adjacency matrix for edge predictions\n",
    "    edge_pred_3d = triu_to_3d_dense(edge_pred, node_pred.shape[0]) # [num nodes, num nodes, edge types]\n",
    "\n",
    "    # Recover full 3d adjacency matrix for edge targets\n",
    "    edge_tar_3d = triu_to_3d_dense(edge_tar, node_tar.shape[0]) # [num nodes, num nodes, edge types]\n",
    "    \n",
    "    # --- The two output matrices tell us how many edges are connected with each of the atom types\n",
    "    # Multiply each of the edge types with the atom types for the predictions\n",
    "    node_edge_preds = torch.empty((MAX_MOLECULE_SIZE, len(SUPPORTED_ATOMS), len(SUPPORTED_EDGES)), dtype=torch.float, device=device)\n",
    "    for edge in range(len(SUPPORTED_EDGES)):\n",
    "        node_edge_preds[:, :, edge] = torch.matmul(edge_pred_3d[:, :, edge], node_pred[:, :9])\n",
    "\n",
    "    # Multiply each of the edge types with the atom types for the targets\n",
    "    node_edge_tar = torch.empty((node_tar.shape[0], len(SUPPORTED_ATOMS), len(SUPPORTED_EDGES)), dtype=torch.float, device=device)\n",
    "    for edge in range(len(SUPPORTED_EDGES)):\n",
    "        node_edge_tar[:, :, edge] = torch.matmul(edge_tar_3d[:, :, edge], node_tar.float())\n",
    "    \n",
    "    # Reduce to matrix with [num atom types, num edge types]\n",
    "    node_edge_pred_matrix = torch.sum(node_edge_preds, dim=0)\n",
    "    node_edge_tar_matrix = torch.sum(node_edge_tar, dim=0)\n",
    "\n",
    "    if torch.equal(node_edge_pred_matrix.int(), node_edge_tar_matrix.int()):\n",
    "        print(\"Reconstructed node-edge pairs: \", node_edge_pred_matrix.int())\n",
    "    \n",
    "    node_edge_loss = torch.mean(sum(squared_difference(node_edge_pred_matrix, node_edge_tar_matrix.float())))\n",
    "\n",
    "    # Calculate node-edge-node for preds\n",
    "    node_edge_node_preds = torch.empty((MAX_MOLECULE_SIZE, MAX_MOLECULE_SIZE, len(SUPPORTED_EDGES)), dtype=torch.float, device=device)\n",
    "    for edge in range(len(SUPPORTED_EDGES)):\n",
    "        node_edge_node_preds[:, :, edge] = torch.matmul(node_edge_preds[:, :, edge], node_pred[:, :9].t())\n",
    "\n",
    "    # Calculate node-edge-node for targets\n",
    "    node_edge_node_tar = torch.empty((node_tar.shape[0], node_tar.shape[0], len(SUPPORTED_EDGES)), dtype=torch.float, device=device)\n",
    "    for edge in range(len(SUPPORTED_EDGES)):\n",
    "        node_edge_node_tar[:, :, edge] = torch.matmul(node_edge_tar[:, :, edge], node_tar.float().t())\n",
    "\n",
    "    # Node edge node loss\n",
    "    node_edge_node_loss = sum(squared_difference(torch.sum(node_edge_node_preds, [0,1]), \n",
    "                                                 torch.sum(node_edge_node_tar, [0,1])))\n",
    "\n",
    "    # TODO: Improve loss\n",
    "    return node_edge_loss #  * node_edge_node_loss\n",
    "\n",
    "\n",
    "def approximate_recon_loss(node_targets, node_preds, triu_targets, triu_preds):\n",
    "    \"\"\"\n",
    "    See: https://github.com/seokhokang/graphvae_approx/\n",
    "    TODO: Improve loss function \n",
    "    \"\"\"\n",
    "    # Convert targets to one hot\n",
    "    onehot_node_targets = to_one_hot(node_targets, SUPPORTED_ATOMS ) #+ [\"None\"]\n",
    "    onehot_triu_targets = to_one_hot(triu_targets, [\"None\"] + SUPPORTED_EDGES)\n",
    "\n",
    "    # Reshape node predictions\n",
    "    node_matrix_shape = (MAX_MOLECULE_SIZE, (len(SUPPORTED_ATOMS) + 1)) \n",
    "    node_preds_matrix = node_preds.reshape(node_matrix_shape)\n",
    "\n",
    "    # Reshape triu predictions \n",
    "    edge_matrix_shape = (int((MAX_MOLECULE_SIZE * (MAX_MOLECULE_SIZE - 1))/2), len(SUPPORTED_EDGES) + 1) \n",
    "    triu_preds_matrix = triu_preds.reshape(edge_matrix_shape)\n",
    "\n",
    "    # Apply sum on labels per (node/edge) type and discard \"none\" types\n",
    "    node_preds_reduced = torch.sum(node_preds_matrix[:, :9], 0)\n",
    "    node_targets_reduced = torch.sum(onehot_node_targets, 0)\n",
    "    triu_preds_reduced = torch.sum(triu_preds_matrix[:, 1:], 0)\n",
    "    triu_targets_reduced = torch.sum(onehot_triu_targets[:, 1:], 0)\n",
    "    \n",
    "    # Calculate node-sum loss and edge-sum loss\n",
    "    node_loss = sum(squared_difference(node_preds_reduced, node_targets_reduced.float()))\n",
    "    edge_loss = sum(squared_difference(triu_preds_reduced, triu_targets_reduced.float()))\n",
    "\n",
    "    # Calculate node-edge-sum loss\n",
    "    # Forces the model to properly arrange the matrices\n",
    "    node_edge_loss = calculate_node_edge_pair_loss(onehot_node_targets, \n",
    "                                      onehot_triu_targets, \n",
    "                                      node_preds_matrix, \n",
    "                                      triu_preds_matrix)\n",
    "\n",
    "    approx_loss =   node_loss  + edge_loss + node_edge_loss\n",
    "\n",
    "    if all(node_targets_reduced == node_preds_reduced.int()) and \\\n",
    "        all(triu_targets_reduced == triu_preds_reduced.int()):\n",
    "        print(\"Reconstructed all edges: \", node_targets_reduced)\n",
    "        print(\"and all nodes: \", node_targets_reduced)\n",
    "    return approx_loss\n",
    "\n",
    "\n",
    "def gvae_loss(triu_logits, node_logits, edge_index, edge_types, node_types, \\\n",
    "              mu, logvar, batch_index, kl_beta):\n",
    "    \"\"\"\n",
    "    Calculates the loss for the graph variational autoencoder,\n",
    "    consiting of a node loss, an edge loss and the KL divergence.\n",
    "    \"\"\"\n",
    "    # Convert target edge index to dense adjacency matrix\n",
    "    batch_edge_targets = torch.squeeze(to_dense_adj(edge_index))\n",
    "\n",
    "    # Add edge types to adjacency targets\n",
    "    batch_edge_targets[edge_index[0], edge_index[1]] = edge_types[:, 1].float()\n",
    "\n",
    "    # For this model we always have the same (fixed) output dimension\n",
    "    graph_size = MAX_MOLECULE_SIZE*(len(SUPPORTED_ATOMS) + 1) \n",
    "    graph_triu_size = int((MAX_MOLECULE_SIZE * (MAX_MOLECULE_SIZE - 1)) / 2) * (len(SUPPORTED_EDGES) + 1)\n",
    "\n",
    "    # Reconstruction loss per graph\n",
    "    batch_recon_loss = []\n",
    "    triu_indices_counter = 0\n",
    "    graph_size_counter = 0\n",
    "\n",
    "    # Loop over graphs in this batch\n",
    "    for graph_id in torch.unique(batch_index):   \n",
    "            # Get upper triangular targets for this graph from the whole batch\n",
    "            triu_targets, node_targets = slice_graph_targets(graph_id, \n",
    "                                                            batch_edge_targets, \n",
    "                                                            node_types,\n",
    "                                                            batch_index)\n",
    "\n",
    "            # Get upper triangular predictions for this graph from the whole batch\n",
    "            triu_preds, node_preds = slice_graph_predictions(triu_logits, \n",
    "                                                            node_logits, \n",
    "                                                            graph_triu_size, \n",
    "                                                            triu_indices_counter, \n",
    "                                                            graph_size, \n",
    "                                                            graph_size_counter)\n",
    "\n",
    "            # Update counter to the index of the next (upper-triu) graph\n",
    "            triu_indices_counter = triu_indices_counter + graph_triu_size\n",
    "            graph_size_counter = graph_size_counter + graph_size\n",
    "\n",
    "            # Calculate losses\n",
    "            recon_loss = approximate_recon_loss(node_targets, \n",
    "                                                node_preds, \n",
    "                                                triu_targets, \n",
    "                                                triu_preds)\n",
    "            batch_recon_loss.append(recon_loss)   \n",
    "\n",
    "    # Take average of all losses\n",
    "    num_graphs = torch.unique(batch_index).shape[0]\n",
    "    batch_recon_loss = torch.true_divide(sum(batch_recon_loss),  num_graphs)\n",
    "    \n",
    "    # KL Divergence\n",
    "    kl_divergence = kl_loss(mu, logvar)\n",
    "\n",
    "    return batch_recon_loss + kl_beta * kl_divergence, kl_divergence\n",
    "\n",
    "\n",
    "\n",
    "def graph_representation_to_molecule(node_types, adjacency_triu):\n",
    "    \"\"\"\n",
    "    Converts the predicted graph to a molecule and validates it\n",
    "    using RDKit.\n",
    "    \"\"\"\n",
    "    # Create empty mol\n",
    "    mol = Chem.RWMol()\n",
    "\n",
    "    # Add atoms to mol and store their index\n",
    "    node_to_idx = {}\n",
    "    for i in range(len(node_types)):\n",
    "        a = Chem.Atom(int(node_types[i]))\n",
    "        molIdx = mol.AddAtom(a)\n",
    "        node_to_idx[i] = molIdx\n",
    "    \n",
    "    # Add edges to mol\n",
    "    num_nodes = len(node_types)\n",
    "    adjacency_matrix = triu_to_dense(adjacency_triu, num_nodes)\n",
    "    for ix, row in enumerate(adjacency_matrix):\n",
    "        for iy, bond in enumerate(row):\n",
    "            # only traverse half the matrix\n",
    "            if iy <= ix:\n",
    "                continue\n",
    "\n",
    "            # add bonds\n",
    "            if bond == 0:\n",
    "                continue\n",
    "            else:\n",
    "                if bond == 1:\n",
    "                    bond_type = Chem.rdchem.BondType.SINGLE\n",
    "                elif bond == 2:\n",
    "                    bond_type = Chem.rdchem.BondType.DOUBLE\n",
    "                elif bond == 3:\n",
    "                    bond_type = Chem.rdchem.BondType.TRIPLE\n",
    "                elif bond == 4:\n",
    "                    bond_type = Chem.rdchem.BondType.AROMATIC\n",
    "                mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
    "    # Convert RWMol to mol and Smiles\n",
    "    mol = mol.GetMol()\n",
    "    smiles = Chem.MolToSmiles(mol)\n",
    "\n",
    "    # Sanitize molecule (make sure it is valid)\n",
    "    try:\n",
    "        Chem.SanitizeMol(mol)\n",
    "    except:\n",
    "        smiles = None\n",
    "\n",
    "    # TODO: Visualize and save (use deepchem smiles_to_image)\n",
    "    return smiles, mol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
